1、回归：回归，指研究一组随机变量(Y1 ，Y2 ，…，Yi)和另一组(X1，X2，…，Xk)变量之间关系的统计分析方法，又称多重回归分析。
    回归分析是一种数学模型。当因变量和自变量为线性关系时，它是一种特殊的线性模型。当函数为参数未知的线性函数时，称为线性回归分析模型；
    当函数为参数未知的非线性函数时，称为非线性回归分析模型。当自变量个数大于1时称为多元回归，当因变量个数大于1时称为多重回归。

2、回归分析的主要内容有以下：
    ①从一组数据出发，确定某些变量之间的定量关系式；即建立数学模型并估计未知参数。通常用最小二乘法。
    ②检验这些关系式的可信任程度。
    ③在多个自变量影响一个因变量的关系中，判断自变量的影响是否显著，并将影响显著的选入模型中，剔除不显著的变量。通常用逐步回归、向前回归和向后回归等方法。
    ④利用所求的关系式对某一过程进行预测或控制。

3、回归主要的种类有：线性回归、曲线回归、二元logistic回归、多元logistic回归。

4、在大数据分析中，回归分析是一种预测性的建模技术，它研究的是因变量（目标）和自变量（预测器）之间的关系。这种技术通常用于预测分析，时间序列模型以及发现变量之间的因果关系。

5、Linear Regression线性回归：线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。
   Logistic Regression逻辑回归：逻辑回归是用来计算“事件=Success”和“事件=Failure”的概率。当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，我们就应该使用逻辑回归。
                              在这里我们使用的是的二项分布（因变量），我们需要选择一个对于这个分布最佳的连结函数。它就是Logit函数。在上述方程中，通过观测样本的极大似然估计值来选择参数，而不是最小化平方和误差。
    Polynomial Regression多项式回归：对于一个回归方程，如果自变量的指数大于1，那么它就是多项式回归方程。

6、迭代:重复反馈过程的活动，其目的通常是为了逼近所需目标或结果。每一次对过程的重复称为一次“迭代”，而每一次迭代得到的结果会作为下一次迭代的初始值。
    重复执行一系列运算步骤，从前面的量依次求出后面的量的过程。此过程的每一次结果，都是由对前一次所得结果施行相同的运算步骤得到的。
    对计算机特定程序中需要反复执行的子程序*(一组指令)，进行一次重复，即重复执行程序中的循环，直到满足某条件为止，亦称为迭代。

7、