导入库

数据
    读取数据
    数据预处理：清洗、转换
    数据可视化分析：观察比较、特征提取
    数据拆分：训练集、测试集
    数据归一化、标准化

 模型
    模型选择
    模型训练
    模型优化
        损失函数（即最优化目标函数）：交叉熵函数
        训练方法（即最优化算法）：梯度下降法
        
    模型测试

    模型验证
        交叉验证

    模型评估
        预测精度

统计分析
    分类判断
    精度对比：最佳模型、参数

模型应用评估
    加载模型
    随机提取测试集的一组数据和标签测试
    预测精度






交叉熵(Cross Entropy)
    交叉熵可在神经网络(机器学习)中作为损失函数，p表示真实标记的分布，q则为训练后的模型的预测标记分布，交叉熵损失函数可以衡量p与q的相似性。
    交叉熵作为损失函数还有一个好处是使用sigmoid函数在梯度下降时能避免均方误差损失函数学习速率降低的问题，因为学习速率可以被输出的误差所控制。
    交叉熵用来衡量预测值和真实值的相似程度，如果完全相同，它们的交叉熵等于零 ,所以loss 越小学的好。


交叉验证(Cross-validation)
    交叉验证主要用于回归建模中。在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。
    这个过程一直进行，直到所有的样本都被预报了一次而且仅被预报一次。把每个样本的预报误差平方加和，称为PRESS(predicted Error Sum of Squares)。
    通常并不会把所有的数据集都拿来训练，而是分出一部分来（这一部分不参加训练）对训练集生成的参数进行测试，相对客观的判断这些参数对训练集之外的数据的符合程度。这种思想就称为交叉验证。

    交叉验证的基本思想是把在某种意义下将原始数据(dataset)进行分组,一部分做为训练集(train set),另一部分做为验证集(validation set or test set),首先用训练集对分类器进行训练,
    再利用验证集来测试训练得到的模型(model),以此来做为评价分类器的性能指标。
    交叉验证的目的是为了得到可靠稳定的模型。在建立PCR 或PLS 模型时，一个很重要的因素是取多少个主成分的问题。用cross validation 校验每个主成分下的PRESS值，选择PRESS值小的主成分数。
    或PRESS值不再变小时的主成分数。

    K-fold cross-validation：K折交叉验证，初始采样分割成K个子样本，一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用来训练。交叉验证重复K次，每个子样本验证一次，
    平均K次的结果或者使用其它结合方式，最终得到一个单一估测。


